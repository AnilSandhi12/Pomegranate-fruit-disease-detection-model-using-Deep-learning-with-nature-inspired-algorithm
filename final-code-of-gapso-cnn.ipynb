{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T18:59:09.179950Z",
     "iopub.status.busy": "2025-07-09T18:59:09.179486Z",
     "iopub.status.idle": "2025-07-09T18:59:25.412522Z",
     "shell.execute_reply": "2025-07-09T18:59:25.411589Z",
     "shell.execute_reply.started": "2025-07-09T18:59:09.179926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import random\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import cycle\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T18:59:25.413939Z",
     "iopub.status.busy": "2025-07-09T18:59:25.413505Z",
     "iopub.status.idle": "2025-07-09T18:59:25.513903Z",
     "shell.execute_reply": "2025-07-09T18:59:25.513077Z",
     "shell.execute_reply.started": "2025-07-09T18:59:25.413918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "DATA_PATH = \"/kaggle/input/balanced-pomegranate-dataset/Pomegranate Diseases Dataset\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0002\n",
    "IMG_SIZE = 224\n",
    "NOISE_TYPE = 'speckle'\n",
    "K_FOLDS = 5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"gradcam\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T18:59:25.515267Z",
     "iopub.status.busy": "2025-07-09T18:59:25.514771Z",
     "iopub.status.idle": "2025-07-09T18:59:29.637555Z",
     "shell.execute_reply": "2025-07-09T18:59:29.636905Z",
     "shell.execute_reply.started": "2025-07-09T18:59:25.515248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images in 5 classes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Enhanced Data Preprocessing with Noise Augmentation\n",
    "class NoisyDataset(Dataset):\n",
    "    def __init__(self, dataset, noise_type, noise_level=0.1):\n",
    "        self.dataset = dataset\n",
    "        self.noise_type = noise_type\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def add_noise(self, img):\n",
    "        img = img.clone()\n",
    "        if self.noise_type == 'gaussian':\n",
    "            noise = torch.randn(img.size()) * self.noise_level\n",
    "            return torch.clamp(img + noise, 0, 1)\n",
    "        elif self.noise_type == 'speckle':\n",
    "            salt_pepper = torch.rand(img.size())\n",
    "            img[salt_pepper < self.noise_level/2] = 0\n",
    "            img[salt_pepper > 1 - self.noise_level/2] = 1\n",
    "            return img\n",
    "        elif self.noise_type == 'poisson':\n",
    "            vals = len(torch.unique(img))\n",
    "            vals = 2 ** np.ceil(np.log2(vals))\n",
    "            noisy = torch.poisson(img * vals) / float(vals)\n",
    "            return noisy\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        return self.add_noise(img), label\n",
    "\n",
    "# Preprocessing transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "base_dataset = ImageFolder(root=DATA_PATH, transform=transform)\n",
    "class_names = base_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Found {len(base_dataset)} images in {num_classes} classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T18:59:29.638776Z",
     "iopub.status.busy": "2025-07-09T18:59:29.638414Z",
     "iopub.status.idle": "2025-07-09T18:59:29.653221Z",
     "shell.execute_reply": "2025-07-09T18:59:29.652354Z",
     "shell.execute_reply.started": "2025-07-09T18:59:29.638746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Enhanced Model with Grad-CAM++ Hooks\n",
    "class FineTunedResNet101(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super().__init__()\n",
    "        base_model = models.resnet101(pretrained=True)\n",
    "        \n",
    "        # Feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            base_model.conv1,\n",
    "            base_model.bn1,\n",
    "            base_model.relu,\n",
    "            base_model.maxpool,\n",
    "            base_model.layer1,\n",
    "            base_model.layer2,\n",
    "            base_model.layer3,\n",
    "            base_model.layer4\n",
    "        )\n",
    "        \n",
    "        # Grad-CAM++ hooks\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "        \n",
    "        # Register hooks\n",
    "        self.hook_handles = [\n",
    "            self.features.register_forward_hook(self.forward_hook),\n",
    "            self.features.register_full_backward_hook(self.backward_hook)\n",
    "        ]\n",
    "        \n",
    "        # Classifier\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive_pool(x).flatten(1)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        with torch.no_grad():\n",
    "            features = self.features(x)\n",
    "            return self.adaptive_pool(features).flatten(1)\n",
    "    \n",
    "    def forward_hook(self, module, input, output):\n",
    "        self.activations = output\n",
    "    \n",
    "    def backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "    \n",
    "    def generate_cam(self):\n",
    "        \"\"\"Generate Grad-CAM++ heatmap\"\"\"\n",
    "        if self.activations is None or self.gradients is None:\n",
    "            return None\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            # Grad-CAM++ calculations\n",
    "            gradients_squared = self.gradients.pow(2)\n",
    "            gradients_cubed = self.gradients.pow(3)\n",
    "            alpha = gradients_squared / (2 * gradients_squared + \n",
    "                                        gradients_cubed.sum(dim=(2, 3), keepdim=True) + 1e-6)\n",
    "            weights = (alpha * torch.clamp(self.gradients, min=0)).sum(dim=(2, 3), keepdim=True)\n",
    "            \n",
    "            cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "            cam = torch.relu(cam)\n",
    "            cam_min = cam.min()\n",
    "            cam_max = cam.max()\n",
    "            if cam_max - cam_min > 0:\n",
    "                cam = (cam - cam_min) / (cam_max - cam_min)\n",
    "            else:\n",
    "                cam = torch.zeros_like(cam)\n",
    "        return cam\n",
    "    \n",
    "    def release_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T18:59:29.654165Z",
     "iopub.status.busy": "2025-07-09T18:59:29.653930Z",
     "iopub.status.idle": "2025-07-09T18:59:29.677849Z",
     "shell.execute_reply": "2025-07-09T18:59:29.677311Z",
     "shell.execute_reply.started": "2025-07-09T18:59:29.654138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 4. Enhanced GA-PSO Implementation\n",
    "def fitness_function(x, features, labels):\n",
    "    selected = x > 0.5  # Convert continuous to binary\n",
    "    if np.sum(selected) == 0:\n",
    "        return 0.0\n",
    "    X = features[:, selected]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, stratify=labels)\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn.score(X_test, y_test)\n",
    "\n",
    "def initialize_population(pop_size, dim, bounds):\n",
    "    return np.random.uniform(bounds[0], bounds[1], (pop_size, dim)), np.zeros((pop_size, dim))\n",
    "\n",
    "def tournament_selection(pop, fitness, tournament_size):\n",
    "    selected = []\n",
    "    for _ in range(len(pop)):\n",
    "        candidates = np.random.choice(len(pop), tournament_size, replace=False)\n",
    "        selected.append(pop[candidates[np.argmax(fitness[candidates])]])\n",
    "    return np.array(selected)\n",
    "\n",
    "def uniform_crossover(parent1, parent2, crossover_rate):\n",
    "    if np.random.rand() < crossover_rate:\n",
    "        mask = np.random.randint(0, 2, parent1.shape)\n",
    "        return np.where(mask, parent1, parent2), np.where(mask, parent2, parent1)\n",
    "    return parent1.copy(), parent2.copy()\n",
    "\n",
    "def mutate(child, mutation_rate, bounds):\n",
    "    mask = np.random.rand(len(child)) < mutation_rate\n",
    "    child[mask] = np.random.uniform(bounds[0], bounds[1], sum(mask))\n",
    "    return child\n",
    "\n",
    "def gso_optimizer(features, labels, pop_size=30, dim=100, bounds=(0,1), hc=0.5,\n",
    "                 max_iter=50, ga_params=(0.8, 0.1, 3), pso_params=(0.7, 1.5, 1.5)):\n",
    "    # Initialize population\n",
    "    pop, velocities = initialize_population(pop_size, dim, bounds)\n",
    "    fitness = np.array([fitness_function(ind, features, labels) for ind in pop])\n",
    "\n",
    "    pbest_positions = pop.copy()\n",
    "    pbest_fitness = fitness.copy()\n",
    "    gbest_idx = np.argmax(pbest_fitness)\n",
    "    gbest_position = pbest_positions[gbest_idx].copy()\n",
    "    gbest_fitness = pbest_fitness[gbest_idx]\n",
    "\n",
    "    omega, phi1, phi2 = pso_params\n",
    "    crossover_rate, mutation_rate, tournament_size = ga_params\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "        # GA operations\n",
    "        n_ga = int(hc * pop_size)\n",
    "        ga_indices = np.random.choice(pop_size, n_ga, replace=False)\n",
    "        selected = tournament_selection(pop[ga_indices], fitness[ga_indices], tournament_size)\n",
    "        offspring = []\n",
    "        for i in range(0, len(selected), 2):\n",
    "            p1, p2 = selected[i], selected[i+1] if i+1 < len(selected) else selected[i]\n",
    "            c1, c2 = uniform_crossover(p1, p2, crossover_rate)\n",
    "            offspring.extend([mutate(c1, mutation_rate, bounds), mutate(c2, mutation_rate, bounds)])\n",
    "        pop[ga_indices] = np.array(offspring[:n_ga])\n",
    "\n",
    "        # PSO operations\n",
    "        pso_indices = np.setdiff1d(np.arange(pop_size), ga_indices)\n",
    "        for i in pso_indices:\n",
    "            r1, r2 = np.random.rand(2)\n",
    "            velocities[i] = omega*velocities[i] + phi1*r1*(pbest_positions[i]-pop[i]) + phi2*r2*(gbest_position-pop[i])\n",
    "            pop[i] = np.clip(pop[i] + velocities[i], bounds[0], bounds[1])\n",
    "\n",
    "        # Update fitness\n",
    "        fitness = np.array([fitness_function(ind, features, labels) for ind in pop])\n",
    "        improved = fitness > pbest_fitness\n",
    "        pbest_positions[improved] = pop[improved]\n",
    "        pbest_fitness[improved] = fitness[improved]\n",
    "\n",
    "        if pbest_fitness.max() > gbest_fitness:\n",
    "            gbest_idx = np.argmax(pbest_fitness)\n",
    "            gbest_position = pbest_positions[gbest_idx].copy()\n",
    "            gbest_fitness = pbest_fitness[gbest_idx]\n",
    "\n",
    "        print(f\"Iteration {iter+1}/{max_iter}: Best Fitness = {gbest_fitness:.4f}\")\n",
    "\n",
    "    return gbest_position > 0.5  # Return binary mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T18:59:29.678869Z",
     "iopub.status.busy": "2025-07-09T18:59:29.678630Z",
     "iopub.status.idle": "2025-07-09T18:59:29.704059Z",
     "shell.execute_reply": "2025-07-09T18:59:29.703401Z",
     "shell.execute_reply.started": "2025-07-09T18:59:29.678846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. Enhanced Training and Evaluation Functions\n",
    "def train_model(model, train_loader, criterion, optimizer, scheduler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    all_probs = np.vstack(all_probs)\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels, all_probs\n",
    "\n",
    "def extract_features(model, loader):\n",
    "    model.eval()\n",
    "    features, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(loader, desc=\"Extracting features\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            feats = model.extract_features(inputs).cpu().numpy()\n",
    "            features.append(feats)\n",
    "            labels.append(targets.numpy())\n",
    "    return np.vstack(features), np.concatenate(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T18:59:29.706238Z",
     "iopub.status.busy": "2025-07-09T18:59:29.705863Z",
     "iopub.status.idle": "2025-07-09T18:59:29.731222Z",
     "shell.execute_reply": "2025-07-09T18:59:29.730657Z",
     "shell.execute_reply.started": "2025-07-09T18:59:29.706218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 6. Enhanced Visualization Functions\n",
    "def visualize_gradcam(model, dataloader, fold, num_samples=5):\n",
    "    model.eval()\n",
    "    samples = random.sample(range(len(dataloader.dataset)), num_samples)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3 * num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(samples):\n",
    "        image, true_label = dataloader.dataset[idx]\n",
    "        input_tensor = image.unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(input_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        pred_class = pred.item()\n",
    "        \n",
    "        # Generate CAM\n",
    "        model.zero_grad()\n",
    "        output[0, pred_class].backward(retain_graph=True)\n",
    "        cam = model.generate_cam()\n",
    "        \n",
    "        if cam is None:\n",
    "            continue\n",
    "            \n",
    "        # Process CAM\n",
    "        cam = cam.squeeze().cpu().detach().numpy()\n",
    "        cam = cv2.resize(cam, (IMG_SIZE, IMG_SIZE))\n",
    "        cam = np.uint8(255 * cam)\n",
    "        heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Original image\n",
    "        denorm = transforms.Compose([\n",
    "            transforms.Normalize(mean=[0, 0, 0], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "            transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
    "            transforms.ToPILImage()\n",
    "        ])\n",
    "        orig_img = denorm(image.cpu())\n",
    "        orig_img = np.array(orig_img)\n",
    "        \n",
    "        # Overlay heatmap\n",
    "        overlay = cv2.addWeighted(orig_img, 0.6, heatmap, 0.4, 0)\n",
    "        \n",
    "        # Plot\n",
    "        plt.subplot(num_samples, 3, 3*i+1)\n",
    "        plt.imshow(orig_img)\n",
    "        plt.title(f\"Original\\nLabel: {class_names[true_label]}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_samples, 3, 3*i+2)\n",
    "        plt.imshow(heatmap)\n",
    "        plt.title(f\"Grad-CAM++ Heatmap\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_samples, 3, 3*i+3)\n",
    "        plt.imshow(overlay)\n",
    "        plt.title(f\"Overlay\\nPred: {class_names[pred_class]}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"gradcam/fold_{fold+1}_gradcam.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Release hooks after visualization\n",
    "    model.release_hooks()\n",
    "\n",
    "def plot_roc_curve(y_true, y_score, class_names, fold):\n",
    "    \"\"\"Plot ROC curve with enhanced visualization\"\"\"\n",
    "    # Binarize the labels\n",
    "    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(class_names)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Compute micro-average ROC curve and area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Get color map\n",
    "    colors = plt.cm.get_cmap('viridis', len(class_names))\n",
    "    \n",
    "    # Generate color values\n",
    "    color_values = colors(np.linspace(0, 1, len(class_names)))\n",
    "    \n",
    "    # Plot each class\n",
    "    for i, color in zip(range(len(class_names)), color_values):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "    \n",
    "    # Plot micro-average\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label=f'Micro-average (AUC = {roc_auc[\"micro\"]:.2f})',\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "    \n",
    "    # Plot diagonal\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    \n",
    "    # Format plot\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-class ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/fold_{fold+1}_roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T18:59:29.732357Z",
     "iopub.status.busy": "2025-07-09T18:59:29.732055Z",
     "iopub.status.idle": "2025-07-09T18:59:29.751389Z",
     "shell.execute_reply": "2025-07-09T18:59:29.750663Z",
     "shell.execute_reply.started": "2025-07-09T18:59:29.732329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_learning_curves(history_orig, history_noisy, fold):\n",
    "    \"\"\"Plot loss and accuracy curves for original and noisy models\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history_orig['train_loss'], label='Original Model', linestyle='-', linewidth=2)\n",
    "    plt.plot(history_noisy['train_loss'], label='Noisy Model', linestyle='--', linewidth=2)\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history_orig['val_loss'], label='Original Model', linestyle='-', linewidth=2)\n",
    "    plt.plot(history_noisy['val_loss'], label='Noisy Model', linestyle='--', linewidth=2)\n",
    "    plt.title('Validation Loss Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Accuracy curves\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history_orig['train_acc'], label='Original Model', linestyle='-', linewidth=2)\n",
    "    plt.plot(history_noisy['train_acc'], label='Noisy Model', linestyle='--', linewidth=2)\n",
    "    plt.title('Training Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(history_orig['val_acc'], label='Original Model', linestyle='-', linewidth=2)\n",
    "    plt.plot(history_noisy['val_acc'], label='Noisy Model', linestyle='--', linewidth=2)\n",
    "    plt.title('Validation Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/fold_{fold+1}_learning_curves.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_pca(features, labels, title, fold):\n",
    "    \"\"\"Visualize features using PCA\"\"\"\n",
    "    pca = PCA(n_components=2)\n",
    "    components = pca.fit_transform(features)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(components[:, 0], components[:, 1], c=labels, \n",
    "                         cmap='viridis', alpha=0.6, edgecolor='k', s=40)\n",
    "    plt.colorbar(scatter, label='Class')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f\"results/fold_{fold+1}_{title.replace(' ', '_')}.png\", dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T18:59:29.752740Z",
     "iopub.status.busy": "2025-07-09T18:59:29.752254Z",
     "iopub.status.idle": "2025-07-10T02:48:55.057541Z",
     "shell.execute_reply": "2025-07-10T02:48:55.056702Z",
     "shell.execute_reply.started": "2025-07-09T18:59:29.752716Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "STARTING FOLD 1/5\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:00<00:00, 210MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training original model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [03:06<00:00,  1.49s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [01:02<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.2020 | Acc: 0.9413 | Val Loss: 0.0776 | Acc: 0.9760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:07<00:00,  1.98s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:58<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.1058 | Acc: 0.9685 | Val Loss: 0.0490 | Acc: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:04<00:00,  1.96s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:59<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.0689 | Acc: 0.9805 | Val Loss: 0.0372 | Acc: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:05<00:00,  1.96s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [01:00<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0376 | Acc: 0.9875 | Val Loss: 0.0246 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:04<00:00,  1.96s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:59<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0161 | Acc: 0.9948 | Val Loss: 0.0303 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:04<00:00,  1.95s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:59<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0113 | Acc: 0.9968 | Val Loss: 0.0226 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:01<00:00,  1.93s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:58<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0085 | Acc: 0.9970 | Val Loss: 0.0234 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [03:59<00:00,  1.91s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:58<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0061 | Acc: 0.9992 | Val Loss: 0.0234 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:03<00:00,  1.94s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:57<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0084 | Acc: 0.9972 | Val Loss: 0.0214 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [03:57<00:00,  1.90s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:59<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0075 | Acc: 0.9978 | Val Loss: 0.0252 | Acc: 0.9920\n",
      "\n",
      "Training noisy model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:05<00:00,  1.96s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:59<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.2325 | Acc: 0.9263 | Val Loss: 0.0695 | Acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:05<00:00,  1.96s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [01:00<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.1153 | Acc: 0.9633 | Val Loss: 0.1543 | Acc: 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:00<00:00,  1.92s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:58<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.0869 | Acc: 0.9758 | Val Loss: 0.1138 | Acc: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [03:58<00:00,  1.91s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:59<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0422 | Acc: 0.9872 | Val Loss: 0.0309 | Acc: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:10<00:00,  2.00s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [01:03<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0220 | Acc: 0.9932 | Val Loss: 0.0371 | Acc: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:16<00:00,  2.06s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [01:00<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0235 | Acc: 0.9940 | Val Loss: 0.0261 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:06<00:00,  1.98s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [01:00<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0166 | Acc: 0.9950 | Val Loss: 0.0257 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:09<00:00,  1.99s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [01:01<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0164 | Acc: 0.9955 | Val Loss: 0.0342 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:05<00:00,  1.97s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [01:01<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0176 | Acc: 0.9960 | Val Loss: 0.0220 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [04:06<00:00,  1.97s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [01:01<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0127 | Acc: 0.9958 | Val Loss: 0.0247 | Acc: 0.9920\n",
      "\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [03:58<00:00,  1.91s/it]\n",
      "Extracting features: 100%|██████████| 125/125 [04:04<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused features shape: (4000, 4096)\n",
      "\n",
      "Running GSO optimization...\n",
      "Iteration 1/50: Best Fitness = 1.0000\n",
      "Iteration 2/50: Best Fitness = 1.0000\n",
      "Iteration 3/50: Best Fitness = 1.0000\n",
      "Iteration 4/50: Best Fitness = 1.0000\n",
      "Iteration 5/50: Best Fitness = 1.0000\n",
      "Iteration 6/50: Best Fitness = 1.0000\n",
      "Iteration 7/50: Best Fitness = 1.0000\n",
      "Iteration 8/50: Best Fitness = 1.0000\n",
      "Iteration 9/50: Best Fitness = 1.0000\n",
      "Iteration 10/50: Best Fitness = 1.0000\n",
      "Iteration 11/50: Best Fitness = 1.0000\n",
      "Iteration 12/50: Best Fitness = 1.0000\n",
      "Iteration 13/50: Best Fitness = 1.0000\n",
      "Iteration 14/50: Best Fitness = 1.0000\n",
      "Iteration 15/50: Best Fitness = 1.0000\n",
      "Iteration 16/50: Best Fitness = 1.0000\n",
      "Iteration 17/50: Best Fitness = 1.0000\n",
      "Iteration 18/50: Best Fitness = 1.0000\n",
      "Iteration 19/50: Best Fitness = 1.0000\n",
      "Iteration 20/50: Best Fitness = 1.0000\n",
      "Iteration 21/50: Best Fitness = 1.0000\n",
      "Iteration 22/50: Best Fitness = 1.0000\n",
      "Iteration 23/50: Best Fitness = 1.0000\n",
      "Iteration 24/50: Best Fitness = 1.0000\n",
      "Iteration 25/50: Best Fitness = 1.0000\n",
      "Iteration 26/50: Best Fitness = 1.0000\n",
      "Iteration 27/50: Best Fitness = 1.0000\n",
      "Iteration 28/50: Best Fitness = 1.0000\n",
      "Iteration 29/50: Best Fitness = 1.0000\n",
      "Iteration 30/50: Best Fitness = 1.0000\n",
      "Iteration 31/50: Best Fitness = 1.0000\n",
      "Iteration 32/50: Best Fitness = 1.0000\n",
      "Iteration 33/50: Best Fitness = 1.0000\n",
      "Iteration 34/50: Best Fitness = 1.0000\n",
      "Iteration 35/50: Best Fitness = 1.0000\n",
      "Iteration 36/50: Best Fitness = 1.0000\n",
      "Iteration 37/50: Best Fitness = 1.0000\n",
      "Iteration 38/50: Best Fitness = 1.0000\n",
      "Iteration 39/50: Best Fitness = 1.0000\n",
      "Iteration 40/50: Best Fitness = 1.0000\n",
      "Iteration 41/50: Best Fitness = 1.0000\n",
      "Iteration 42/50: Best Fitness = 1.0000\n",
      "Iteration 43/50: Best Fitness = 1.0000\n",
      "Iteration 44/50: Best Fitness = 1.0000\n",
      "Iteration 45/50: Best Fitness = 1.0000\n",
      "Iteration 46/50: Best Fitness = 1.0000\n",
      "Iteration 47/50: Best Fitness = 1.0000\n",
      "Iteration 48/50: Best Fitness = 1.0000\n",
      "Iteration 49/50: Best Fitness = 1.0000\n",
      "Iteration 50/50: Best Fitness = 1.0000\n",
      "Selected 2042 features (49.85%)\n",
      "MLP Validation Accuracy: 0.9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]\n",
      "Extracting features: 100%|██████████| 32/32 [00:59<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST ACCURACY FOR FOLD 1: 0.9930\n",
      "\n",
      "Generating Grad-CAM++ visualizations...\n",
      "\n",
      "Visualizing feature spaces...\n",
      "\n",
      "Generating ROC curve...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76/2624469537.py:88: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = plt.cm.get_cmap('viridis', len(class_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Values: {0: 0.9999822845804989, 1: 0.9998960363872644, 2: 0.9999613242574258, 3: 0.9998794454490657, 4: 1.0, 'micro': 0.99995575}\n",
      "\n",
      "Generating confusion matrix...\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Alternaria       0.99      1.00      1.00       216\n",
      "     Anthracnose       0.98      0.99      0.98       190\n",
      "Bacterial_Blight       1.00      0.99      1.00       192\n",
      "      Cercospora       1.00      0.98      0.99       210\n",
      "         Healthy       1.00      1.00      1.00       192\n",
      "\n",
      "        accuracy                           0.99      1000\n",
      "       macro avg       0.99      0.99      0.99      1000\n",
      "    weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "\n",
      "FOLD 1 COMPLETED IN 119m 49s\n",
      "\n",
      "========================================\n",
      "STARTING FOLD 2/5\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training original model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.1986 | Acc: 0.9415 | Val Loss: 0.1144 | Acc: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.0930 | Acc: 0.9735 | Val Loss: 0.0541 | Acc: 0.9820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.0819 | Acc: 0.9760 | Val Loss: 0.0603 | Acc: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0423 | Acc: 0.9878 | Val Loss: 0.0330 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0233 | Acc: 0.9932 | Val Loss: 0.0284 | Acc: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:51<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0249 | Acc: 0.9915 | Val Loss: 0.0288 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0145 | Acc: 0.9955 | Val Loss: 0.0310 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0150 | Acc: 0.9958 | Val Loss: 0.0300 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:43<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0132 | Acc: 0.9960 | Val Loss: 0.0286 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:59<00:00,  1.43s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0113 | Acc: 0.9972 | Val Loss: 0.0246 | Acc: 0.9910\n",
      "\n",
      "Training noisy model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.2117 | Acc: 0.9350 | Val Loss: 0.0783 | Acc: 0.9770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.1161 | Acc: 0.9667 | Val Loss: 0.1413 | Acc: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.1003 | Acc: 0.9688 | Val Loss: 0.0621 | Acc: 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0439 | Acc: 0.9852 | Val Loss: 0.0315 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0307 | Acc: 0.9918 | Val Loss: 0.0329 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:56<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0254 | Acc: 0.9932 | Val Loss: 0.0340 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0205 | Acc: 0.9935 | Val Loss: 0.0297 | Acc: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0178 | Acc: 0.9950 | Val Loss: 0.0315 | Acc: 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0191 | Acc: 0.9945 | Val Loss: 0.0332 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:51<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:43<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0139 | Acc: 0.9960 | Val Loss: 0.0274 | Acc: 0.9940\n",
      "\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [02:44<00:00,  1.32s/it]\n",
      "Extracting features: 100%|██████████| 125/125 [02:46<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused features shape: (4000, 4096)\n",
      "\n",
      "Running GSO optimization...\n",
      "Iteration 1/50: Best Fitness = 1.0000\n",
      "Iteration 2/50: Best Fitness = 1.0000\n",
      "Iteration 3/50: Best Fitness = 1.0000\n",
      "Iteration 4/50: Best Fitness = 1.0000\n",
      "Iteration 5/50: Best Fitness = 1.0000\n",
      "Iteration 6/50: Best Fitness = 1.0000\n",
      "Iteration 7/50: Best Fitness = 1.0000\n",
      "Iteration 8/50: Best Fitness = 1.0000\n",
      "Iteration 9/50: Best Fitness = 1.0000\n",
      "Iteration 10/50: Best Fitness = 1.0000\n",
      "Iteration 11/50: Best Fitness = 1.0000\n",
      "Iteration 12/50: Best Fitness = 1.0000\n",
      "Iteration 13/50: Best Fitness = 1.0000\n",
      "Iteration 14/50: Best Fitness = 1.0000\n",
      "Iteration 15/50: Best Fitness = 1.0000\n",
      "Iteration 16/50: Best Fitness = 1.0000\n",
      "Iteration 17/50: Best Fitness = 1.0000\n",
      "Iteration 18/50: Best Fitness = 1.0000\n",
      "Iteration 19/50: Best Fitness = 1.0000\n",
      "Iteration 20/50: Best Fitness = 1.0000\n",
      "Iteration 21/50: Best Fitness = 1.0000\n",
      "Iteration 22/50: Best Fitness = 1.0000\n",
      "Iteration 23/50: Best Fitness = 1.0000\n",
      "Iteration 24/50: Best Fitness = 1.0000\n",
      "Iteration 25/50: Best Fitness = 1.0000\n",
      "Iteration 26/50: Best Fitness = 1.0000\n",
      "Iteration 27/50: Best Fitness = 1.0000\n",
      "Iteration 28/50: Best Fitness = 1.0000\n",
      "Iteration 29/50: Best Fitness = 1.0000\n",
      "Iteration 30/50: Best Fitness = 1.0000\n",
      "Iteration 31/50: Best Fitness = 1.0000\n",
      "Iteration 32/50: Best Fitness = 1.0000\n",
      "Iteration 33/50: Best Fitness = 1.0000\n",
      "Iteration 34/50: Best Fitness = 1.0000\n",
      "Iteration 35/50: Best Fitness = 1.0000\n",
      "Iteration 36/50: Best Fitness = 1.0000\n",
      "Iteration 37/50: Best Fitness = 1.0000\n",
      "Iteration 38/50: Best Fitness = 1.0000\n",
      "Iteration 39/50: Best Fitness = 1.0000\n",
      "Iteration 40/50: Best Fitness = 1.0000\n",
      "Iteration 41/50: Best Fitness = 1.0000\n",
      "Iteration 42/50: Best Fitness = 1.0000\n",
      "Iteration 43/50: Best Fitness = 1.0000\n",
      "Iteration 44/50: Best Fitness = 1.0000\n",
      "Iteration 45/50: Best Fitness = 1.0000\n",
      "Iteration 46/50: Best Fitness = 1.0000\n",
      "Iteration 47/50: Best Fitness = 1.0000\n",
      "Iteration 48/50: Best Fitness = 1.0000\n",
      "Iteration 49/50: Best Fitness = 1.0000\n",
      "Iteration 50/50: Best Fitness = 1.0000\n",
      "Selected 2011 features (49.10%)\n",
      "MLP Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 32/32 [00:43<00:00,  1.34s/it]\n",
      "Extracting features: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST ACCURACY FOR FOLD 2: 0.9900\n",
      "\n",
      "Generating Grad-CAM++ visualizations...\n",
      "\n",
      "Visualizing feature spaces...\n",
      "\n",
      "Generating ROC curve...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76/2624469537.py:88: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = plt.cm.get_cmap('viridis', len(class_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Values: {0: 0.9995441441788496, 1: 0.9999943186983001, 2: 0.998625678119349, 3: 0.9999863309549194, 4: 0.9999935283039626, 'micro': 0.9995565}\n",
      "\n",
      "Generating confusion matrix...\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Alternaria       0.98      0.99      0.98       193\n",
      "     Anthracnose       1.00      1.00      1.00       228\n",
      "Bacterial_Blight       0.98      0.98      0.98       210\n",
      "      Cercospora       0.99      0.99      0.99       178\n",
      "         Healthy       0.99      1.00      1.00       191\n",
      "\n",
      "        accuracy                           0.99      1000\n",
      "       macro avg       0.99      0.99      0.99      1000\n",
      "    weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "\n",
      "FOLD 2 COMPLETED IN 87m 56s\n",
      "\n",
      "========================================\n",
      "STARTING FOLD 3/5\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training original model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.2117 | Acc: 0.9283 | Val Loss: 0.1161 | Acc: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:49<00:00,  1.36s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.1016 | Acc: 0.9670 | Val Loss: 0.0616 | Acc: 0.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:51<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.0690 | Acc: 0.9785 | Val Loss: 0.0534 | Acc: 0.9820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:49<00:00,  1.36s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0334 | Acc: 0.9888 | Val Loss: 0.0248 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:49<00:00,  1.36s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0198 | Acc: 0.9942 | Val Loss: 0.0248 | Acc: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:50<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0132 | Acc: 0.9960 | Val Loss: 0.0237 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:49<00:00,  1.36s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0151 | Acc: 0.9962 | Val Loss: 0.0267 | Acc: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:49<00:00,  1.36s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0098 | Acc: 0.9978 | Val Loss: 0.0217 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:49<00:00,  1.36s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0138 | Acc: 0.9978 | Val Loss: 0.0266 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:50<00:00,  1.36s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0097 | Acc: 0.9972 | Val Loss: 0.0200 | Acc: 0.9930\n",
      "\n",
      "Training noisy model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.2226 | Acc: 0.9265 | Val Loss: 0.1988 | Acc: 0.9440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.1280 | Acc: 0.9593 | Val Loss: 0.0722 | Acc: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:54<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.0948 | Acc: 0.9752 | Val Loss: 0.0921 | Acc: 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0469 | Acc: 0.9872 | Val Loss: 0.0430 | Acc: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0282 | Acc: 0.9910 | Val Loss: 0.0346 | Acc: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:54<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:43<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0322 | Acc: 0.9905 | Val Loss: 0.0254 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:51<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0232 | Acc: 0.9932 | Val Loss: 0.0241 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0145 | Acc: 0.9962 | Val Loss: 0.0272 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0167 | Acc: 0.9952 | Val Loss: 0.0205 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0159 | Acc: 0.9945 | Val Loss: 0.0280 | Acc: 0.9940\n",
      "\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [02:41<00:00,  1.29s/it]\n",
      "Extracting features: 100%|██████████| 125/125 [02:44<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused features shape: (4000, 4096)\n",
      "\n",
      "Running GSO optimization...\n",
      "Iteration 1/50: Best Fitness = 1.0000\n",
      "Iteration 2/50: Best Fitness = 1.0000\n",
      "Iteration 3/50: Best Fitness = 1.0000\n",
      "Iteration 4/50: Best Fitness = 1.0000\n",
      "Iteration 5/50: Best Fitness = 1.0000\n",
      "Iteration 6/50: Best Fitness = 1.0000\n",
      "Iteration 7/50: Best Fitness = 1.0000\n",
      "Iteration 8/50: Best Fitness = 1.0000\n",
      "Iteration 9/50: Best Fitness = 1.0000\n",
      "Iteration 10/50: Best Fitness = 1.0000\n",
      "Iteration 11/50: Best Fitness = 1.0000\n",
      "Iteration 12/50: Best Fitness = 1.0000\n",
      "Iteration 13/50: Best Fitness = 1.0000\n",
      "Iteration 14/50: Best Fitness = 1.0000\n",
      "Iteration 15/50: Best Fitness = 1.0000\n",
      "Iteration 16/50: Best Fitness = 1.0000\n",
      "Iteration 17/50: Best Fitness = 1.0000\n",
      "Iteration 18/50: Best Fitness = 1.0000\n",
      "Iteration 19/50: Best Fitness = 1.0000\n",
      "Iteration 20/50: Best Fitness = 1.0000\n",
      "Iteration 21/50: Best Fitness = 1.0000\n",
      "Iteration 22/50: Best Fitness = 1.0000\n",
      "Iteration 23/50: Best Fitness = 1.0000\n",
      "Iteration 24/50: Best Fitness = 1.0000\n",
      "Iteration 25/50: Best Fitness = 1.0000\n",
      "Iteration 26/50: Best Fitness = 1.0000\n",
      "Iteration 27/50: Best Fitness = 1.0000\n",
      "Iteration 28/50: Best Fitness = 1.0000\n",
      "Iteration 29/50: Best Fitness = 1.0000\n",
      "Iteration 30/50: Best Fitness = 1.0000\n",
      "Iteration 31/50: Best Fitness = 1.0000\n",
      "Iteration 32/50: Best Fitness = 1.0000\n",
      "Iteration 33/50: Best Fitness = 1.0000\n",
      "Iteration 34/50: Best Fitness = 1.0000\n",
      "Iteration 35/50: Best Fitness = 1.0000\n",
      "Iteration 36/50: Best Fitness = 1.0000\n",
      "Iteration 37/50: Best Fitness = 1.0000\n",
      "Iteration 38/50: Best Fitness = 1.0000\n",
      "Iteration 39/50: Best Fitness = 1.0000\n",
      "Iteration 40/50: Best Fitness = 1.0000\n",
      "Iteration 41/50: Best Fitness = 1.0000\n",
      "Iteration 42/50: Best Fitness = 1.0000\n",
      "Iteration 43/50: Best Fitness = 1.0000\n",
      "Iteration 44/50: Best Fitness = 1.0000\n",
      "Iteration 45/50: Best Fitness = 1.0000\n",
      "Iteration 46/50: Best Fitness = 1.0000\n",
      "Iteration 47/50: Best Fitness = 1.0000\n",
      "Iteration 48/50: Best Fitness = 1.0000\n",
      "Iteration 49/50: Best Fitness = 1.0000\n",
      "Iteration 50/50: Best Fitness = 1.0000\n",
      "Selected 2034 features (49.66%)\n",
      "MLP Validation Accuracy: 0.9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n",
      "Extracting features: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST ACCURACY FOR FOLD 3: 0.9910\n",
      "\n",
      "Generating Grad-CAM++ visualizations...\n",
      "\n",
      "Visualizing feature spaces...\n",
      "\n",
      "Generating ROC curve...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76/2624469537.py:88: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = plt.cm.get_cmap('viridis', len(class_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Values: {0: 0.9999141370109113, 1: 0.9999011069837012, 2: 0.9999069455817762, 3: 1.0, 4: 1.0, 'micro': 0.99994525}\n",
      "\n",
      "Generating confusion matrix...\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Alternaria       0.99      0.99      0.99       186\n",
      "     Anthracnose       0.99      0.98      0.99       203\n",
      "Bacterial_Blight       0.99      0.99      0.99       202\n",
      "      Cercospora       0.99      1.00      0.99       202\n",
      "         Healthy       1.00      1.00      1.00       207\n",
      "\n",
      "        accuracy                           0.99      1000\n",
      "       macro avg       0.99      0.99      0.99      1000\n",
      "    weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "\n",
      "FOLD 3 COMPLETED IN 87m 34s\n",
      "\n",
      "========================================\n",
      "STARTING FOLD 4/5\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training original model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:46<00:00,  1.33s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.1916 | Acc: 0.9413 | Val Loss: 0.0911 | Acc: 0.9740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:47<00:00,  1.34s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:39<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.0804 | Acc: 0.9755 | Val Loss: 0.0904 | Acc: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:46<00:00,  1.33s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.0972 | Acc: 0.9720 | Val Loss: 0.1037 | Acc: 0.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:47<00:00,  1.34s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0457 | Acc: 0.9855 | Val Loss: 0.0314 | Acc: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:47<00:00,  1.34s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0286 | Acc: 0.9910 | Val Loss: 0.0250 | Acc: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:46<00:00,  1.33s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0206 | Acc: 0.9940 | Val Loss: 0.0234 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:46<00:00,  1.33s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0183 | Acc: 0.9948 | Val Loss: 0.0215 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:46<00:00,  1.33s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0157 | Acc: 0.9952 | Val Loss: 0.0269 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:47<00:00,  1.34s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0205 | Acc: 0.9940 | Val Loss: 0.0176 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:46<00:00,  1.33s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0203 | Acc: 0.9945 | Val Loss: 0.0152 | Acc: 0.9940\n",
      "\n",
      "Training noisy model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:50<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.2431 | Acc: 0.9197 | Val Loss: 0.1868 | Acc: 0.9410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.1079 | Acc: 0.9670 | Val Loss: 0.0993 | Acc: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.0822 | Acc: 0.9758 | Val Loss: 0.0632 | Acc: 0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:59<00:00,  1.43s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:43<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0392 | Acc: 0.9890 | Val Loss: 0.0296 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0281 | Acc: 0.9918 | Val Loss: 0.0304 | Acc: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:43<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0174 | Acc: 0.9948 | Val Loss: 0.0231 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:54<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0177 | Acc: 0.9950 | Val Loss: 0.0298 | Acc: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:57<00:00,  1.42s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0150 | Acc: 0.9970 | Val Loss: 0.0223 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:51<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0142 | Acc: 0.9958 | Val Loss: 0.0187 | Acc: 0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:43<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0150 | Acc: 0.9952 | Val Loss: 0.0227 | Acc: 0.9930\n",
      "\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [02:44<00:00,  1.31s/it]\n",
      "Extracting features: 100%|██████████| 125/125 [02:47<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused features shape: (4000, 4096)\n",
      "\n",
      "Running GSO optimization...\n",
      "Iteration 1/50: Best Fitness = 1.0000\n",
      "Iteration 2/50: Best Fitness = 1.0000\n",
      "Iteration 3/50: Best Fitness = 1.0000\n",
      "Iteration 4/50: Best Fitness = 1.0000\n",
      "Iteration 5/50: Best Fitness = 1.0000\n",
      "Iteration 6/50: Best Fitness = 1.0000\n",
      "Iteration 7/50: Best Fitness = 1.0000\n",
      "Iteration 8/50: Best Fitness = 1.0000\n",
      "Iteration 9/50: Best Fitness = 1.0000\n",
      "Iteration 10/50: Best Fitness = 1.0000\n",
      "Iteration 11/50: Best Fitness = 1.0000\n",
      "Iteration 12/50: Best Fitness = 1.0000\n",
      "Iteration 13/50: Best Fitness = 1.0000\n",
      "Iteration 14/50: Best Fitness = 1.0000\n",
      "Iteration 15/50: Best Fitness = 1.0000\n",
      "Iteration 16/50: Best Fitness = 1.0000\n",
      "Iteration 17/50: Best Fitness = 1.0000\n",
      "Iteration 18/50: Best Fitness = 1.0000\n",
      "Iteration 19/50: Best Fitness = 1.0000\n",
      "Iteration 20/50: Best Fitness = 1.0000\n",
      "Iteration 21/50: Best Fitness = 1.0000\n",
      "Iteration 22/50: Best Fitness = 1.0000\n",
      "Iteration 23/50: Best Fitness = 1.0000\n",
      "Iteration 24/50: Best Fitness = 1.0000\n",
      "Iteration 25/50: Best Fitness = 1.0000\n",
      "Iteration 26/50: Best Fitness = 1.0000\n",
      "Iteration 27/50: Best Fitness = 1.0000\n",
      "Iteration 28/50: Best Fitness = 1.0000\n",
      "Iteration 29/50: Best Fitness = 1.0000\n",
      "Iteration 30/50: Best Fitness = 1.0000\n",
      "Iteration 31/50: Best Fitness = 1.0000\n",
      "Iteration 32/50: Best Fitness = 1.0000\n",
      "Iteration 33/50: Best Fitness = 1.0000\n",
      "Iteration 34/50: Best Fitness = 1.0000\n",
      "Iteration 35/50: Best Fitness = 1.0000\n",
      "Iteration 36/50: Best Fitness = 1.0000\n",
      "Iteration 37/50: Best Fitness = 1.0000\n",
      "Iteration 38/50: Best Fitness = 1.0000\n",
      "Iteration 39/50: Best Fitness = 1.0000\n",
      "Iteration 40/50: Best Fitness = 1.0000\n",
      "Iteration 41/50: Best Fitness = 1.0000\n",
      "Iteration 42/50: Best Fitness = 1.0000\n",
      "Iteration 43/50: Best Fitness = 1.0000\n",
      "Iteration 44/50: Best Fitness = 1.0000\n",
      "Iteration 45/50: Best Fitness = 1.0000\n",
      "Iteration 46/50: Best Fitness = 1.0000\n",
      "Iteration 47/50: Best Fitness = 1.0000\n",
      "Iteration 48/50: Best Fitness = 1.0000\n",
      "Iteration 49/50: Best Fitness = 1.0000\n",
      "Iteration 50/50: Best Fitness = 1.0000\n",
      "Selected 2067 features (50.46%)\n",
      "MLP Validation Accuracy: 0.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n",
      "Extracting features: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST ACCURACY FOR FOLD 4: 0.9880\n",
      "\n",
      "Generating Grad-CAM++ visualizations...\n",
      "\n",
      "Visualizing feature spaces...\n",
      "\n",
      "Generating ROC curve...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76/2624469537.py:88: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = plt.cm.get_cmap('viridis', len(class_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Values: {0: 0.9997992252456538, 1: 0.9999868986479404, 2: 0.9997659035121161, 3: 0.9997309921498618, 4: 1.0, 'micro': 0.999694125}\n",
      "\n",
      "Generating confusion matrix...\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Alternaria       1.00      0.96      0.98       216\n",
      "     Anthracnose       1.00      0.99      0.99       188\n",
      "Bacterial_Blight       0.95      1.00      0.97       183\n",
      "      Cercospora       1.00      1.00      1.00       206\n",
      "         Healthy       1.00      1.00      1.00       207\n",
      "\n",
      "        accuracy                           0.99      1000\n",
      "       macro avg       0.99      0.99      0.99      1000\n",
      "    weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "\n",
      "FOLD 4 COMPLETED IN 86m 36s\n",
      "\n",
      "========================================\n",
      "STARTING FOLD 5/5\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training original model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.2185 | Acc: 0.9347 | Val Loss: 0.0575 | Acc: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.0797 | Acc: 0.9780 | Val Loss: 0.0547 | Acc: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.0803 | Acc: 0.9738 | Val Loss: 0.0633 | Acc: 0.9820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:50<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0319 | Acc: 0.9908 | Val Loss: 0.0256 | Acc: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:40<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0183 | Acc: 0.9948 | Val Loss: 0.0248 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0147 | Acc: 0.9962 | Val Loss: 0.0197 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0141 | Acc: 0.9955 | Val Loss: 0.0169 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:51<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0122 | Acc: 0.9970 | Val Loss: 0.0214 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0095 | Acc: 0.9980 | Val Loss: 0.0194 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:50<00:00,  1.36s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0104 | Acc: 0.9972 | Val Loss: 0.0187 | Acc: 0.9940\n",
      "\n",
      "Training noisy model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:57<00:00,  1.42s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.2354 | Acc: 0.9335 | Val Loss: 0.1732 | Acc: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:54<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.1001 | Acc: 0.9698 | Val Loss: 0.0921 | Acc: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:56<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.1064 | Acc: 0.9673 | Val Loss: 0.0507 | Acc: 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0512 | Acc: 0.9842 | Val Loss: 0.0285 | Acc: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:57<00:00,  1.42s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0283 | Acc: 0.9922 | Val Loss: 0.0264 | Acc: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:56<00:00,  1.42s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0300 | Acc: 0.9912 | Val Loss: 0.0221 | Acc: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:56<00:00,  1.42s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0174 | Acc: 0.9945 | Val Loss: 0.0208 | Acc: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:56<00:00,  1.42s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0131 | Acc: 0.9962 | Val Loss: 0.0213 | Acc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:56<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0250 | Acc: 0.9918 | Val Loss: 0.0255 | Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [02:51<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0172 | Acc: 0.9955 | Val Loss: 0.0153 | Acc: 0.9950\n",
      "\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [02:38<00:00,  1.27s/it]\n",
      "Extracting features: 100%|██████████| 125/125 [02:45<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused features shape: (4000, 4096)\n",
      "\n",
      "Running GSO optimization...\n",
      "Iteration 1/50: Best Fitness = 1.0000\n",
      "Iteration 2/50: Best Fitness = 1.0000\n",
      "Iteration 3/50: Best Fitness = 1.0000\n",
      "Iteration 4/50: Best Fitness = 1.0000\n",
      "Iteration 5/50: Best Fitness = 1.0000\n",
      "Iteration 6/50: Best Fitness = 1.0000\n",
      "Iteration 7/50: Best Fitness = 1.0000\n",
      "Iteration 8/50: Best Fitness = 1.0000\n",
      "Iteration 9/50: Best Fitness = 1.0000\n",
      "Iteration 10/50: Best Fitness = 1.0000\n",
      "Iteration 11/50: Best Fitness = 1.0000\n",
      "Iteration 12/50: Best Fitness = 1.0000\n",
      "Iteration 13/50: Best Fitness = 1.0000\n",
      "Iteration 14/50: Best Fitness = 1.0000\n",
      "Iteration 15/50: Best Fitness = 1.0000\n",
      "Iteration 16/50: Best Fitness = 1.0000\n",
      "Iteration 17/50: Best Fitness = 1.0000\n",
      "Iteration 18/50: Best Fitness = 1.0000\n",
      "Iteration 19/50: Best Fitness = 1.0000\n",
      "Iteration 20/50: Best Fitness = 1.0000\n",
      "Iteration 21/50: Best Fitness = 1.0000\n",
      "Iteration 22/50: Best Fitness = 1.0000\n",
      "Iteration 23/50: Best Fitness = 1.0000\n",
      "Iteration 24/50: Best Fitness = 1.0000\n",
      "Iteration 25/50: Best Fitness = 1.0000\n",
      "Iteration 26/50: Best Fitness = 1.0000\n",
      "Iteration 27/50: Best Fitness = 1.0000\n",
      "Iteration 28/50: Best Fitness = 1.0000\n",
      "Iteration 29/50: Best Fitness = 1.0000\n",
      "Iteration 30/50: Best Fitness = 1.0000\n",
      "Iteration 31/50: Best Fitness = 1.0000\n",
      "Iteration 32/50: Best Fitness = 1.0000\n",
      "Iteration 33/50: Best Fitness = 1.0000\n",
      "Iteration 34/50: Best Fitness = 1.0000\n",
      "Iteration 35/50: Best Fitness = 1.0000\n",
      "Iteration 36/50: Best Fitness = 1.0000\n",
      "Iteration 37/50: Best Fitness = 1.0000\n",
      "Iteration 38/50: Best Fitness = 1.0000\n",
      "Iteration 39/50: Best Fitness = 1.0000\n",
      "Iteration 40/50: Best Fitness = 1.0000\n",
      "Iteration 41/50: Best Fitness = 1.0000\n",
      "Iteration 42/50: Best Fitness = 1.0000\n",
      "Iteration 43/50: Best Fitness = 1.0000\n",
      "Iteration 44/50: Best Fitness = 1.0000\n",
      "Iteration 45/50: Best Fitness = 1.0000\n",
      "Iteration 46/50: Best Fitness = 1.0000\n",
      "Iteration 47/50: Best Fitness = 1.0000\n",
      "Iteration 48/50: Best Fitness = 1.0000\n",
      "Iteration 49/50: Best Fitness = 1.0000\n",
      "Iteration 50/50: Best Fitness = 1.0000\n",
      "Selected 2035 features (49.68%)\n",
      "MLP Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]\n",
      "Extracting features: 100%|██████████| 32/32 [00:43<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST ACCURACY FOR FOLD 5: 0.9910\n",
      "\n",
      "Generating Grad-CAM++ visualizations...\n",
      "\n",
      "Visualizing feature spaces...\n",
      "\n",
      "Generating ROC curve...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76/2624469537.py:88: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = plt.cm.get_cmap('viridis', len(class_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Values: {0: 0.999895615185381, 1: 0.9999676415198131, 2: 0.9998150700049514, 3: 1.0, 4: 1.0, 'micro': 0.99995325}\n",
      "\n",
      "Generating confusion matrix...\n",
      "\n",
      "Classification Report for Fold 5:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Alternaria       0.98      0.98      0.98       189\n",
      "     Anthracnose       0.99      0.99      0.99       191\n",
      "Bacterial_Blight       0.99      0.98      0.98       213\n",
      "      Cercospora       1.00      1.00      1.00       204\n",
      "         Healthy       1.00      1.00      1.00       203\n",
      "\n",
      "        accuracy                           0.99      1000\n",
      "       macro avg       0.99      0.99      0.99      1000\n",
      "    weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "\n",
      "FOLD 5 COMPLETED IN 87m 30s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. K-Fold Cross Validation with Enhanced Tracking\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "results = {}\n",
    "fold_accuracies = []\n",
    "history = {}\n",
    "gso_masks = []\n",
    "mlp_classifiers = []\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(base_dataset)):\n",
    "    fold_start = time.time()\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"STARTING FOLD {fold+1}/{K_FOLDS}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_base = Subset(base_dataset, train_ids)\n",
    "    test_base = Subset(base_dataset, test_ids)\n",
    "    \n",
    "    # Apply noise augmentation\n",
    "    train_noisy = NoisyDataset(train_base, NOISE_TYPE)\n",
    "    test_noisy = NoisyDataset(test_base, NOISE_TYPE)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader_orig = DataLoader(train_base, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    test_loader_orig = DataLoader(test_base, batch_size=BATCH_SIZE, num_workers=4)\n",
    "    train_loader_noisy = DataLoader(train_noisy, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    test_loader_noisy = DataLoader(test_noisy, batch_size=BATCH_SIZE, num_workers=4)\n",
    "    \n",
    "    # Initialize models\n",
    "    model_orig = FineTunedResNet101(num_classes=num_classes).to(DEVICE)\n",
    "    model_noisy = FineTunedResNet101(num_classes=num_classes).to(DEVICE)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_orig = optim.Adam(model_orig.parameters(), lr=LEARNING_RATE)\n",
    "    optimizer_noisy = optim.Adam(model_noisy.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler_orig = optim.lr_scheduler.StepLR(optimizer_orig, step_size=3, gamma=0.1)\n",
    "    scheduler_noisy = optim.lr_scheduler.StepLR(optimizer_noisy, step_size=3, gamma=0.1)\n",
    "    \n",
    "    # Train both models with history tracking\n",
    "    print(\"\\nTraining original model:\")\n",
    "    orig_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc = train_model(\n",
    "            model_orig, train_loader_orig, criterion, optimizer_orig, scheduler_orig)\n",
    "        val_loss, val_acc, _, _, _ = evaluate_model(model_orig, test_loader_orig, criterion)\n",
    "        \n",
    "        orig_history['train_loss'].append(train_loss)\n",
    "        orig_history['train_acc'].append(train_acc)\n",
    "        orig_history['val_loss'].append(val_loss)\n",
    "        orig_history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    print(\"\\nTraining noisy model:\")\n",
    "    noisy_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc = train_model(\n",
    "            model_noisy, train_loader_noisy, criterion, optimizer_noisy, scheduler_noisy)\n",
    "        val_loss, val_acc, _, _, _ = evaluate_model(model_noisy, test_loader_noisy, criterion)\n",
    "        \n",
    "        noisy_history['train_loss'].append(train_loss)\n",
    "        noisy_history['train_acc'].append(train_acc)\n",
    "        noisy_history['val_loss'].append(val_loss)\n",
    "        noisy_history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Store history\n",
    "    history[fold] = {\n",
    "        'orig': orig_history,\n",
    "        'noisy': noisy_history\n",
    "    }\n",
    "    \n",
    "    # Plot learning curves\n",
    "    plot_learning_curves(orig_history, noisy_history, fold)\n",
    "    \n",
    "    # Feature extraction\n",
    "    print(\"\\nExtracting features...\")\n",
    "    features_orig, labels_orig = extract_features(model_orig, train_loader_orig)\n",
    "    features_noisy, labels_noisy = extract_features(model_noisy, train_loader_noisy)\n",
    "    \n",
    "    # Feature fusion\n",
    "    fused_features = np.concatenate((features_orig, features_noisy), axis=1)\n",
    "    print(f\"Fused features shape: {fused_features.shape}\")\n",
    "    \n",
    "    # GSO feature selection\n",
    "    print(\"\\nRunning GSO optimization...\")\n",
    "    best_mask = gso_optimizer(fused_features, labels_orig, dim=fused_features.shape[1],\n",
    "                             pop_size=30, max_iter=50, bounds=(0,1))\n",
    "    selected_features = fused_features[:, best_mask]\n",
    "    selected_count = np.sum(best_mask)\n",
    "    print(f\"Selected {selected_count} features ({selected_count/fused_features.shape[1]*100:.2f}%)\")\n",
    "    \n",
    "    # Train MLP classifier on selected features\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        selected_features, labels_orig, test_size=0.2, stratify=labels_orig)\n",
    "    \n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=(512, 256),\n",
    "        max_iter=1000,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_acc = clf.score(X_val, y_val)\n",
    "    print(f\"MLP Validation Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # Prepare test features\n",
    "    test_features_orig, test_labels = extract_features(model_orig, test_loader_orig)\n",
    "    test_features_noisy, _ = extract_features(model_noisy, test_loader_noisy)\n",
    "    fused_test_features = np.concatenate((test_features_orig, test_features_noisy), axis=1)\n",
    "    selected_test_features = fused_test_features[:, best_mask]\n",
    "    \n",
    "    # Final evaluation\n",
    "    test_acc = clf.score(selected_test_features, test_labels)\n",
    "    fold_accuracies.append(test_acc)\n",
    "    print(f\"\\nTEST ACCURACY FOR FOLD {fold+1}: {test_acc:.4f}\")\n",
    "    \n",
    "    # Save predictions for comprehensive report\n",
    "    test_preds = clf.predict(selected_test_features)\n",
    "    test_probs = clf.predict_proba(selected_test_features)\n",
    "    \n",
    "    # Save results\n",
    "    results[fold] = {\n",
    "        'test_labels': test_labels,\n",
    "        'test_preds': test_preds,\n",
    "        'test_probs': test_probs,\n",
    "        'test_acc': test_acc,\n",
    "        'gso_mask': best_mask,\n",
    "        'selected_count': selected_count\n",
    "    }\n",
    "    \n",
    "    gso_masks.append(best_mask)\n",
    "    mlp_classifiers.append(clf)\n",
    "    \n",
    "    # Grad-CAM visualization\n",
    "    print(\"\\nGenerating Grad-CAM++ visualizations...\")\n",
    "    visualize_gradcam(model_noisy, test_loader_noisy, fold, num_samples=3)\n",
    "    \n",
    "    # Feature visualization\n",
    "    print(\"\\nVisualizing feature spaces...\")\n",
    "    plot_feature_pca(features_orig, labels_orig, \"PCA of Original Features\", fold)\n",
    "    plot_feature_pca(features_noisy, labels_orig, \"PCA of Noisy Features\", fold)\n",
    "    plot_feature_pca(fused_features, labels_orig, \"PCA of Fused Features\", fold)\n",
    "    plot_feature_pca(selected_features, labels_orig, \"PCA of Selected Features after GSO\", fold)\n",
    "    \n",
    "    # ROC Curve\n",
    "    print(\"\\nGenerating ROC curve...\")\n",
    "    roc_auc_values = plot_roc_curve(test_labels, test_probs, class_names, fold)\n",
    "    print(f\"ROC AUC Values: {roc_auc_values}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\nGenerating confusion matrix...\")\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix - Fold {fold+1}')\n",
    "    plt.savefig(f'results/fold_{fold+1}_confusion_matrix.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(test_labels, test_preds, target_names=class_names)\n",
    "    print(f\"\\nClassification Report for Fold {fold+1}:\\n{report}\")\n",
    "    \n",
    "    fold_time = time.time() - fold_start\n",
    "    print(f\"\\nFOLD {fold+1} COMPLETED IN {fold_time//60:.0f}m {fold_time%60:.0f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T02:49:05.485933Z",
     "iopub.status.busy": "2025-07-10T02:49:05.485673Z",
     "iopub.status.idle": "2025-07-10T02:49:06.911614Z",
     "shell.execute_reply": "2025-07-10T02:49:06.910776Z",
     "shell.execute_reply.started": "2025-07-10T02:49:05.485914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "FINAL RESULTS:\n",
      "Average Test Accuracy: 0.9906 ± 0.0016\n",
      "Fold Accuracies: ['0.9930', '0.9900', '0.9910', '0.9880', '0.9910']\n",
      "\n",
      "Overall Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Alternaria       0.99      0.98      0.99      1000\n",
      "     Anthracnose       0.99      0.99      0.99      1000\n",
      "Bacterial_Blight       0.98      0.99      0.98      1000\n",
      "      Cercospora       0.99      0.99      0.99      1000\n",
      "         Healthy       1.00      1.00      1.00      1000\n",
      "\n",
      "        accuracy                           0.99      5000\n",
      "       macro avg       0.99      0.99      0.99      5000\n",
      "    weighted avg       0.99      0.99      0.99      5000\n",
      "\n",
      "\n",
      "Training complete! All results saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 8. Final Performance Analysis\n",
    "print(\"\\n\\nFINAL RESULTS:\")\n",
    "avg_acc = np.mean(fold_accuracies)\n",
    "std_acc = np.std(fold_accuracies)\n",
    "print(f\"Average Test Accuracy: {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "print(f\"Fold Accuracies: {[f'{acc:.4f}' for acc in fold_accuracies]}\")\n",
    "\n",
    "# Save final results\n",
    "final_results = {\n",
    "    'fold_accuracies': fold_accuracies,\n",
    "    'avg_acc': avg_acc,\n",
    "    'std_acc': std_acc,\n",
    "    'class_names': class_names,\n",
    "    'history': history,\n",
    "    'gso_masks': gso_masks,\n",
    "    'mlp_classifiers': mlp_classifiers\n",
    "}\n",
    "torch.save(final_results, 'results/final_results.pth')\n",
    "\n",
    "# Generate comprehensive report\n",
    "all_test_labels = np.concatenate([results[fold]['test_labels'] for fold in range(K_FOLDS)])\n",
    "all_test_preds = np.concatenate([results[fold]['test_preds'] for fold in range(K_FOLDS)])\n",
    "\n",
    "final_report = classification_report(all_test_labels, all_test_preds, target_names=class_names)\n",
    "print(\"\\nOverall Classification Report:\")\n",
    "print(final_report)\n",
    "\n",
    "with open('results/classification_report.txt', 'w') as f:\n",
    "    f.write(final_report)\n",
    "\n",
    "# Plot feature selection statistics\n",
    "selected_counts = [results[fold]['selected_count'] for fold in range(K_FOLDS)]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, K_FOLDS+1), selected_counts, color='skyblue')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Number of Selected Features')\n",
    "plt.title('Feature Selection by GSO Across Folds')\n",
    "plt.xticks(range(1, K_FOLDS+1))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.savefig('results/feature_selection_stats.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nTraining complete! All results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7818382,
     "sourceId": 12398170,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
